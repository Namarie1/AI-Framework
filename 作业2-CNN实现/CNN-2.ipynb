{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47526ea",
   "metadata": {},
   "source": [
    "# 使用numpy手写实现CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48797d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10001)\n",
    "\n",
    "class Tensor:\n",
    "    def __init__(self, shape):\n",
    "        self.data = np.zeros(shape=shape, dtype=np.float32) # 存放数据\n",
    "        self.grad = np.zeros(shape=shape, dtype=np.float32) # 存放梯度\n",
    "\n",
    "    def clear_grad(self):\n",
    "        self.grad = np.zeros_like(self.grad)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Tensor shape: {}, data: {}\".format(self.data.shape, self.data)\n",
    "\n",
    "\n",
    "# Tensor的初始化类，目前仅提供Normal初始化和Constant初始化\n",
    "class Initializer:\n",
    "    \"\"\"\n",
    "    基类\n",
    "    \"\"\"\n",
    "    def __init__(self, shape=None, name='initializer'):\n",
    "        self.shape = shape\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "\n",
    "class Constant(Initializer):\n",
    "    def __init__(self, value=0., name='constant initializer', *args, **kwargs):\n",
    "        super().__init__(name=name, *args, **kwargs)\n",
    "        self.value = value\n",
    "\n",
    "    def __call__(self, shape=None, *args, **kwargs):\n",
    "        if shape:\n",
    "            self.shape = shape\n",
    "        assert shape is not None, \"the shape of initializer must not be None.\"\n",
    "        return self.value + np.zeros(shape=self.shape)\n",
    "\n",
    "\n",
    "class Normal(Initializer):\n",
    "    def __init__(self, mean=0., std=0.01, name='normal initializer', *args, **kwargs):\n",
    "        super().__init__(name=name, *args, **kwargs)\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, shape=None, *args, **kwargs):\n",
    "        if shape:\n",
    "            self.shape = shape\n",
    "        assert shape is not None, \"the shape of initializer must not be None.\"\n",
    "        return np.random.normal(self.mean, self.std, size=self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d85ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, name='layer', *args, **kwargs):\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "    \"\"\"\n",
    "    input X, shape: [N, C]\n",
    "    output Y, shape: [N, O]\n",
    "    weight W, shape: [C, O]\n",
    "    bias b, shape: [1, O]\n",
    "    grad dY, shape: [N, O]\n",
    "    forward formula:\n",
    "        Y = X @ W + b   # @表示矩阵乘法\n",
    "    backward formula:\n",
    "        dW = X.T @ dY\n",
    "        db = sum(dY, axis=0)\n",
    "        dX = dY @ W.T\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        name='linear',\n",
    "        weight_attr=Normal(),\n",
    "        bias_attr=Constant(),\n",
    "        *args,\n",
    "        **kwargs\n",
    "        ):\n",
    "        super().__init__(name=name, *args, **kwargs)\n",
    "        self.weights = Tensor((in_features, out_features))\n",
    "        self.weights.data = weight_attr(self.weights.data.shape)\n",
    "        self.bias = Tensor((1, out_features))\n",
    "        self.bias.data = bias_attr(self.bias.data.shape)\n",
    "        self.input = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        output = np.dot(x, self.weights.data) + self.bias.data\n",
    "        return output\n",
    "\n",
    "    def backward(self, gradient):\n",
    "        self.weights.grad += np.dot(self.input.T, gradient)  # dy / dw\n",
    "        self.bias.grad += np.sum(gradient, axis=0, keepdims=True)  # dy / db \n",
    "        input_grad = np.dot(gradient, self.weights.data.T)  # dy / dx\n",
    "        return input_grad\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weights, self.bias]\n",
    "\n",
    "    def __str__(self):\n",
    "        string = \"linear layer, weight shape: {}, bias shape: {}\".format(self.weights.data.shape, self.bias.data.shape)\n",
    "        return string\n",
    "\n",
    "\n",
    "class ReLU(Layer):\n",
    "    \"\"\"\n",
    "    forward formula:\n",
    "        relu = x if x >= 0\n",
    "             = 0 if x < 0\n",
    "    backwawrd formula:\n",
    "        grad = gradient * (x > 0)\n",
    "    \"\"\"\n",
    "    def __init__(self, name='relu', *args, **kwargs):\n",
    "        super().__init__(name=name, *args, **kwargs)\n",
    "        self.activated = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x[x < 0] = 0\n",
    "        self.activated = x\n",
    "        return self.activated\n",
    "\n",
    "    def backward(self, gradient):\n",
    "        return gradient * (self.activated > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "505920fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.graphs = []\n",
    "        self._parameters = []\n",
    "        for arg_layer in args:\n",
    "            if isinstance(arg_layer, Layer):\n",
    "                self.graphs.append(arg_layer)\n",
    "                self._parameters += arg_layer.parameters()\n",
    "\n",
    "    def add(self, layer):\n",
    "        assert isinstance(layer, Layer), \"The type of added layer must be Layer, but got {}.\".format(type(layer))\n",
    "        self.graphs.append(layer)\n",
    "        self._parameters += layer.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for graph in self.graphs:\n",
    "            x = graph(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad):\n",
    "        # grad backward in inverse order of graph\n",
    "        for graph in self.graphs[::-1]:\n",
    "            grad = graph.backward(grad)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "\n",
    "    def __str__(self):\n",
    "        string = 'Sequential:\\n'\n",
    "        for graph in self.graphs:\n",
    "            string += graph.__str__() + '\\n'\n",
    "        return string\n",
    "\n",
    "    def parameters(self):\n",
    "        return self._parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4df418",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    \"\"\"\n",
    "    optimizer base class.\n",
    "    Args:\n",
    "        parameters (Tensor): parameters to be optimized.\n",
    "        learning_rate (float): learning rate. Default: 0.001.\n",
    "        weight_decay (float): The decay weight of parameters. Defaylt: 0.0.\n",
    "        decay_type (str): The type of regularizer. Default: l2.\n",
    "    \"\"\"\n",
    "    def __init__(self, parameters, learning_rate=0.001, weight_decay=0.0, decay_type='l2'):\n",
    "        assert decay_type in ['l1', 'l2'], \"only support decay_type 'l1' and 'l2', but got {}.\".format(decay_type)\n",
    "        self.parameters = parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.decay_type = decay_type\n",
    "\n",
    "    def step(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def clear_grad(self):\n",
    "        for p in self.parameters:\n",
    "            p.clear_grad()\n",
    "\n",
    "    def get_decay(self, g):\n",
    "        if self.decay_type == 'l1':\n",
    "            return self.weight_decay\n",
    "        elif self.decay_type == 'l2':\n",
    "            return self.weight_decay * g\n",
    "\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, momentum=0.9, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.momentum = momentum\n",
    "        self.velocity = []\n",
    "        for p in self.parameters:\n",
    "            self.velocity.append(np.zeros_like(p.grad))\n",
    "\n",
    "    def step(self):\n",
    "        for p, v in zip(self.parameters, self.velocity):\n",
    "            decay = self.get_decay(p.grad)\n",
    "            v = self.momentum * v + p.grad + decay # 动量计算\n",
    "            p.data = p.data - self.learning_rate * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdeccd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLogits(Layer):\n",
    "    \"\"\"\n",
    "    Softmax with logits error:\n",
    "        loss[j] = -input[class] + log(sum(exp(input)))\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction='mean', name='softamxwithlogits', *args, **kwargs):\n",
    "        super().__init__(name=name, *args, **kwargs)\n",
    "        assert reduction in ['mean', 'none', 'sum'], \"reduction only support 'mean', 'none' and 'sum', but got {}.\".format(reduction)\n",
    "        self.reduction = reduction\n",
    "        self.logits = None\n",
    "        self.target = None\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        \"\"\"\n",
    "        :param y (np.ndarray): predicted logits, shape [N, C]\n",
    "        :param target (np.ndarray): target logits, shape [N, 1]\n",
    "        :return: loss\n",
    "        \"\"\"\n",
    "        assert logits.shape[0] == target.shape[0], \"The first fimension of logits and target is not same, logits shape {} cann't match target shape {}.\".format(logits.shape, target.shape)\n",
    "        self.logits = logits\n",
    "        self.target = target\n",
    "        loss = []\n",
    "        for i in range(logits.shape[0]):\n",
    "            loss_i = -logits[i, target.squeeze(-1)[i]] + np.log(np.sum(np.exp(logits[i])))\n",
    "            loss.append(loss_i)\n",
    "        loss = np.array(loss).reshape(target.shape)\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "    def backward(self):\n",
    "        soft_denominator = np.sum(np.exp(self.logits), axis=1, keepdims=True)  # [N, 1]\n",
    "        eq_grad = np.zeros_like(self.logits)\n",
    "        for i in range(self.logits.shape[0]):\n",
    "            eq_grad[i, self.target.squeeze(-1)[i]] = -1\n",
    "        gradient = np.exp(self.logits) / soft_denominator + eq_grad\n",
    "        return gradient\n",
    "\n",
    "# loss_fn = SoftmaxWithLogits()\n",
    "# logits = np.array([[1., 2., 3.]])\n",
    "# target = np.array([[1]])\n",
    "# print(-2 + np.log(np.exp(1)+np.exp(2)+np.exp(3)))\n",
    "# print(logits.shape, target.shape)\n",
    "# print(loss_fn(logits, target))\n",
    "# print(loss_fn.backward(), np.exp(2) / (np.exp(1)+np.exp(2)+np.exp(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46087ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raise NotImplementedError(\"'{}' not implement in class {}\"\n",
    "                                  .format('__getitem__', self.__class__.__name__))\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError(\"'{}' not implement in class {}\"\n",
    "                                  .format('__len__', self.__class__.__name__))\n",
    "\n",
    "\n",
    "# 根据dataset和一些设置，生成每个batch在dataset中的索引\n",
    "class BatchSampler:\n",
    "    def __init__(self, dataset=None, shuffle=False, batch_size=1, drop_last=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.num_data = len(dataset)\n",
    "        if self.drop_last or (self.num_data % batch_size == 0):\n",
    "            self.num_samples = self.num_data // batch_size\n",
    "        else:\n",
    "            self.num_samples = self.num_data // batch_size + 1\n",
    "        indices = np.arange(self.num_data)\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "        if drop_last:\n",
    "            indices = indices[:self.num_samples * batch_size]\n",
    "        self.indices = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __iter__(self):\n",
    "        batch_indices = []\n",
    "        for i in range(self.num_samples):\n",
    "            if (i + 1) * self.batch_size <= self.num_data:\n",
    "                for idx in range(i * self.batch_size, (i + 1) * self.batch_size):\n",
    "                    batch_indices.append(self.indices[idx])\n",
    "                yield batch_indices\n",
    "                batch_indices = []\n",
    "            else:\n",
    "                for idx in range(i * self.batch_size, self.num_data):\n",
    "                    batch_indices.append(self.indices[idx])\n",
    "        if not self.drop_last and len(batch_indices) > 0:\n",
    "            yield batch_indices\n",
    "\n",
    "\n",
    "# 根据sampler生成的索引，从dataset中取数据，并组合成一个batch\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, sampler=BatchSampler, shuffle=False, batch_size=1, drop_last=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_sampler = sampler\n",
    "        self.sampler = self.batch_sampler(dataset, shuffle, batch_size, drop_last)\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sampler)\n",
    "\n",
    "    def __call__(self):\n",
    "        self.__iter__()\n",
    "\n",
    "    def __iter__(self):\n",
    "        for sample_indices in self.sampler:\n",
    "            data_list = []\n",
    "            label_list = []\n",
    "            for indice in sample_indices:\n",
    "                data, label = self.dataset[indice]\n",
    "                data_list.append(data)\n",
    "                label_list.append(label)\n",
    "            yield np.stack(data_list, axis=0), np.stack(label_list, axis=0)\n",
    "        self.sampler = self.batch_sampler(self.dataset, self.shuffle, self.batch_size, self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d12ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.val = 0.\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.val += value\n",
    "        self.count += n\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.val / self.count\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0.\n",
    "        self.count = 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__call__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36bc2b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取cifar数据\n",
    "def read_cifar(data_path):\n",
    "    with open(data_path, 'rb') as f:\n",
    "        data_dict = pickle.load(f, encoding='latin1')\n",
    "        X = data_dict['data']\n",
    "        Y = data_dict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype(\"float\")\n",
    "        Y = np.array(Y).reshape((10000, 1))\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "# 仅训练10000张图片\n",
    "data_path = \"C:/Users/zhangxiaomi/Desktop/cifar-10-batches-py/data_batch_1\"\n",
    "X, Y = read_cifar(data_path)\n",
    "\n",
    "show_number = 5\n",
    "# 显示示例图片，查看数据\n",
    "for i in range(show_number):\n",
    "    img = X[i]\n",
    "    plt.subplot(1, show_number, i + 1)\n",
    "    plt.imshow(img.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1f9cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx] / 255.0, self.Y[idx] # 图像值缩放到[0, 1]\n",
    "\n",
    "# 设置超参数\n",
    "train_number = 8000  # 训练集大小（共10000）\n",
    "epoches = 100   # epoch\n",
    "batch_size = 4  # batch_size\n",
    "learning_rate = 0.009  # 学习率\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b888dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataset accuracy: 0.095\n",
      "epoch: 1. loss: 2.3049159276355193\n",
      "val dataset accuracy: 0.099\n",
      "epoch: 2. loss: 2.3046259197867514\n",
      "val dataset accuracy: 0.0965\n",
      "epoch: 3. loss: 2.2766451270046106\n",
      "val dataset accuracy: 0.17\n",
      "epoch: 4. loss: 2.2312908862174865\n",
      "val dataset accuracy: 0.1775\n",
      "epoch: 5. loss: 2.200715052275066\n",
      "val dataset accuracy: 0.197\n",
      "epoch: 6. loss: 2.1697813990354193\n",
      "val dataset accuracy: 0.225\n",
      "epoch: 7. loss: 2.141608951407009\n",
      "val dataset accuracy: 0.256\n",
      "epoch: 8. loss: 2.115382574276673\n",
      "val dataset accuracy: 0.2715\n",
      "epoch: 9. loss: 2.0898667136625027\n",
      "val dataset accuracy: 0.271\n",
      "epoch: 10. loss: 2.066488080651017\n",
      "val dataset accuracy: 0.328\n",
      "epoch: 11. loss: 2.0444568033479777\n",
      "val dataset accuracy: 0.3265\n",
      "epoch: 12. loss: 2.023447249358284\n",
      "val dataset accuracy: 0.323\n",
      "epoch: 13. loss: 2.0040382719945153\n",
      "val dataset accuracy: 0.3405\n",
      "epoch: 14. loss: 1.986298511678439\n",
      "val dataset accuracy: 0.3345\n",
      "epoch: 15. loss: 1.9692917647006496\n",
      "val dataset accuracy: 0.338\n",
      "epoch: 16. loss: 1.9530942793753394\n",
      "val dataset accuracy: 0.3485\n",
      "epoch: 17. loss: 1.937848002217543\n",
      "val dataset accuracy: 0.3485\n",
      "epoch: 18. loss: 1.9235509533314947\n",
      "val dataset accuracy: 0.3485\n",
      "epoch: 19. loss: 1.909748766569377\n",
      "val dataset accuracy: 0.377\n",
      "epoch: 20. loss: 1.8965254516040693\n",
      "val dataset accuracy: 0.3595\n",
      "epoch: 21. loss: 1.8841336075286914\n",
      "val dataset accuracy: 0.362\n",
      "epoch: 22. loss: 1.871544274963549\n",
      "val dataset accuracy: 0.362\n",
      "epoch: 23. loss: 1.8601436818824535\n",
      "val dataset accuracy: 0.375\n",
      "epoch: 24. loss: 1.8489841242085925\n",
      "val dataset accuracy: 0.3645\n",
      "epoch: 25. loss: 1.8382938980540662\n",
      "val dataset accuracy: 0.368\n",
      "epoch: 26. loss: 1.8280461489524362\n",
      "val dataset accuracy: 0.3685\n",
      "epoch: 27. loss: 1.8178064339259214\n",
      "val dataset accuracy: 0.394\n",
      "epoch: 28. loss: 1.8083110531046171\n",
      "val dataset accuracy: 0.344\n",
      "epoch: 29. loss: 1.7988207868759971\n",
      "val dataset accuracy: 0.372\n",
      "epoch: 30. loss: 1.789637082635739\n",
      "val dataset accuracy: 0.384\n",
      "epoch: 31. loss: 1.7807902952011925\n",
      "val dataset accuracy: 0.387\n",
      "epoch: 32. loss: 1.7724392324349332\n",
      "val dataset accuracy: 0.3925\n",
      "epoch: 33. loss: 1.763969469060948\n",
      "val dataset accuracy: 0.374\n",
      "epoch: 34. loss: 1.7560582546809196\n",
      "val dataset accuracy: 0.3615\n",
      "epoch: 35. loss: 1.7479396385996955\n",
      "val dataset accuracy: 0.377\n",
      "epoch: 36. loss: 1.740554720529237\n",
      "val dataset accuracy: 0.3915\n",
      "epoch: 37. loss: 1.7330833650932045\n",
      "val dataset accuracy: 0.373\n",
      "epoch: 38. loss: 1.726090261215564\n",
      "val dataset accuracy: 0.373\n",
      "epoch: 39. loss: 1.7190296130243499\n",
      "val dataset accuracy: 0.3585\n",
      "epoch: 40. loss: 1.712259101728012\n",
      "val dataset accuracy: 0.384\n",
      "epoch: 41. loss: 1.705560849375024\n",
      "val dataset accuracy: 0.3855\n",
      "epoch: 42. loss: 1.698922307881741\n",
      "val dataset accuracy: 0.391\n",
      "epoch: 43. loss: 1.6923663742318844\n",
      "val dataset accuracy: 0.3885\n",
      "epoch: 44. loss: 1.6857143883680537\n",
      "val dataset accuracy: 0.376\n",
      "epoch: 45. loss: 1.679390579748003\n",
      "val dataset accuracy: 0.37\n",
      "epoch: 46. loss: 1.6731292597443648\n",
      "val dataset accuracy: 0.359\n",
      "epoch: 47. loss: 1.6670224736977417\n",
      "val dataset accuracy: 0.384\n",
      "epoch: 48. loss: 1.661426259033632\n",
      "val dataset accuracy: 0.3775\n",
      "epoch: 49. loss: 1.6554878515694256\n",
      "val dataset accuracy: 0.378\n",
      "epoch: 50. loss: 1.650035846766074\n",
      "val dataset accuracy: 0.3815\n",
      "epoch: 51. loss: 1.644345596630817\n",
      "val dataset accuracy: 0.382\n",
      "epoch: 52. loss: 1.6387869050610735\n",
      "val dataset accuracy: 0.32\n",
      "epoch: 53. loss: 1.6336529230653045\n",
      "val dataset accuracy: 0.3735\n",
      "epoch: 54. loss: 1.6286184219270072\n",
      "val dataset accuracy: 0.374\n",
      "epoch: 55. loss: 1.6239261855478044\n",
      "val dataset accuracy: 0.364\n",
      "epoch: 56. loss: 1.6195041091463453\n",
      "val dataset accuracy: 0.3455\n",
      "epoch: 57. loss: 1.6146015083900451\n",
      "val dataset accuracy: 0.375\n",
      "epoch: 58. loss: 1.6099499968616007\n",
      "val dataset accuracy: 0.394\n",
      "epoch: 59. loss: 1.6050922054784211\n",
      "val dataset accuracy: 0.3965\n",
      "epoch: 60. loss: 1.6004222762789715\n",
      "val dataset accuracy: 0.3995\n",
      "epoch: 61. loss: 1.5958161343772352\n",
      "val dataset accuracy: 0.3885\n",
      "epoch: 62. loss: 1.5913913549071947\n",
      "val dataset accuracy: 0.3795\n",
      "epoch: 63. loss: 1.5871245680445765\n",
      "val dataset accuracy: 0.3665\n",
      "epoch: 64. loss: 1.5826842661561342\n",
      "val dataset accuracy: 0.3765\n",
      "epoch: 65. loss: 1.5783481105287034\n",
      "val dataset accuracy: 0.398\n",
      "epoch: 66. loss: 1.573926703115809\n",
      "val dataset accuracy: 0.3835\n",
      "epoch: 67. loss: 1.5697828983046151\n",
      "val dataset accuracy: 0.3855\n",
      "epoch: 68. loss: 1.565489982781603\n",
      "val dataset accuracy: 0.379\n",
      "epoch: 69. loss: 1.5615453719371726\n",
      "val dataset accuracy: 0.363\n",
      "epoch: 70. loss: 1.5577460313404354\n",
      "val dataset accuracy: 0.376\n",
      "epoch: 71. loss: 1.553805903990172\n",
      "val dataset accuracy: 0.359\n",
      "epoch: 72. loss: 1.5502302034172326\n",
      "val dataset accuracy: 0.363\n",
      "epoch: 73. loss: 1.546434339346502\n",
      "val dataset accuracy: 0.3865\n",
      "epoch: 74. loss: 1.5427731072885564\n",
      "val dataset accuracy: 0.383\n",
      "epoch: 75. loss: 1.5390660684144135\n",
      "val dataset accuracy: 0.375\n",
      "epoch: 76. loss: 1.535396926803946\n",
      "val dataset accuracy: 0.3945\n",
      "epoch: 77. loss: 1.5316902310898555\n",
      "val dataset accuracy: 0.374\n",
      "epoch: 78. loss: 1.5278263801600858\n",
      "val dataset accuracy: 0.369\n",
      "epoch: 79. loss: 1.5242570200837529\n",
      "val dataset accuracy: 0.3555\n",
      "epoch: 80. loss: 1.5210300114514743\n",
      "val dataset accuracy: 0.357\n",
      "epoch: 81. loss: 1.5177896239314261\n",
      "val dataset accuracy: 0.3705\n",
      "epoch: 82. loss: 1.5144070053693859\n",
      "val dataset accuracy: 0.3635\n",
      "epoch: 83. loss: 1.5111380909385235\n",
      "val dataset accuracy: 0.369\n",
      "epoch: 84. loss: 1.5079816312562142\n",
      "val dataset accuracy: 0.3605\n",
      "epoch: 85. loss: 1.5050615981924262\n",
      "val dataset accuracy: 0.37\n",
      "epoch: 86. loss: 1.5018753448353876\n",
      "val dataset accuracy: 0.383\n",
      "epoch: 87. loss: 1.4987648298635874\n",
      "val dataset accuracy: 0.382\n",
      "epoch: 88. loss: 1.4954833808735453\n",
      "val dataset accuracy: 0.3755\n",
      "epoch: 89. loss: 1.492449228498739\n",
      "val dataset accuracy: 0.375\n",
      "epoch: 90. loss: 1.4898590108718344\n",
      "val dataset accuracy: 0.327\n",
      "epoch: 91. loss: 1.4871381784728768\n",
      "val dataset accuracy: 0.36\n",
      "epoch: 92. loss: 1.484419817933518\n",
      "val dataset accuracy: 0.361\n",
      "epoch: 93. loss: 1.481585209590695\n",
      "val dataset accuracy: 0.39\n",
      "epoch: 94. loss: 1.478802733906659\n",
      "val dataset accuracy: 0.3865\n",
      "epoch: 95. loss: 1.4759287430214107\n",
      "val dataset accuracy: 0.3745\n",
      "epoch: 96. loss: 1.4729302267832005\n",
      "val dataset accuracy: 0.372\n",
      "epoch: 97. loss: 1.4699732350502794\n",
      "val dataset accuracy: 0.395\n",
      "epoch: 98. loss: 1.4673820330775091\n",
      "val dataset accuracy: 0.3425\n",
      "epoch: 99. loss: 1.4645767271626946\n",
      "val dataset accuracy: 0.3835\n",
      "epoch: 100. loss: 1.4621944307315056\n"
     ]
    }
   ],
   "source": [
    "# 划分数据集，训练集和验证集\n",
    "train_X, train_Y = X[:train_number], Y[:train_number]\n",
    "val_X, val_Y = X[train_number:], Y[train_number:]\n",
    "\n",
    "# 构建dataloader\n",
    "train_dataset = CifarDataset(train_X, train_Y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "val_dataset = CifarDataset(val_X, val_Y)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n",
    "# 自己实现的模型组网\n",
    "model = Sequential(\n",
    "    Linear(3 * 32 * 32, 64, name='linear1'),\n",
    "    ReLU(name='relu1'),\n",
    "    Linear(64, 128, name='linear2'),\n",
    "    ReLU(name='relu1'),\n",
    "    Linear(128, 64, name='linear3'),\n",
    "    ReLU(name='relu1'),\n",
    "    Linear(64, num_classes, name='linear4'),\n",
    ")\n",
    "opt = SGD(parameters=model.parameters(), learning_rate=learning_rate, weight_decay=0.0, decay_type='l2')\n",
    "loss_fn = SoftmaxWithLogits()\n",
    "\n",
    "# 一个简单的验证函数，计算模型预测的准确率\n",
    "def eval(model, val_dataloader):\n",
    "    predict_labels = []\n",
    "    labels = []\n",
    "    for x, y in val_dataloader:\n",
    "        x = x.reshape((1, -1))\n",
    "        logits = model(x)\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        predict_labels.append(pred)\n",
    "        labels.append(y.squeeze(1))\n",
    "    pred = np.array(predict_labels)\n",
    "    labels = np.array(labels)\n",
    "    acc = np.sum(pred == labels) / len(labels)\n",
    "    print(\"val dataset accuracy:\", acc)\n",
    "    return acc\n",
    "\n",
    "# 开始训练\n",
    "lddl_acc = []   \n",
    "loss_avg = AverageMeter()\n",
    "for epoch in range(1, epoches + 1):\n",
    "    acc = eval(model, val_dataloader=val_dataloader)  # 先计算一下在验证集上的模型准确率\n",
    "    lddl_acc.append(acc)  \n",
    "    for idx, (x, y) in enumerate(train_dataloader):\n",
    "        x = x.reshape((batch_size, -1))  # 因为用的全连接层实现分类，这里需要先reshape，修改数据维度为[batch_size, channels * H * W]\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "        loss_avg.update(loss)\n",
    "\n",
    "        grad = loss_fn.backward()\n",
    "        model.backward(grad)\n",
    "\n",
    "        opt.step()\n",
    "        opt.clear_grad()\n",
    "    print(\"epoch: {}. loss: {}\".format(epoch, loss_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ced4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466504d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ffd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
