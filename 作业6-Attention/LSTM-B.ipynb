{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233cb0f0-d821-40a1-8c2c-304a15d1a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9fc2bf3-95d0-4479-b63f-a83f8d697f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_CUDA: True\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print('USE_CUDA: %s' % USE_CUDA)\n",
    "SEGMENTATION = True    # 是否分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865cc9af-5571-49e0-a98b-2d368eafe65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.!?，。？]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9491f03-ce02-4b33-bd37-f8b1c9a4d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "\n",
    "class Lang(object):\n",
    "    \"\"\"\n",
    "    词表Vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", '2': 'UNK'}\n",
    "        self.n_words = 3 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        if self.name == 'cn':\n",
    "            words = list(jieba.cut(sentence)) if SEGMENTATION else sentence    \n",
    "            for word in words:\n",
    "                self.index_word(word)\n",
    "        else:\n",
    "            words = sentence.split(' ')\n",
    "            for word in words:\n",
    "                self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4081ee41-9fce-45db-8b90-8e0f33ec1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('%s-%s.txt' % (lang1, lang2)).read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04305de-f262-4d44-b491-1f4dc6349a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79122520-a762-4e9e-8f74-5f78954d242f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 90000 sentence pairs\n",
      "Trimmed to 68898 sentence pairs\n",
      "Indexing words...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.578 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['隨時問任何問題都可以。', 'feel free to ask any questions .']\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('cn', 'eng', False)\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dce8645-4ce5-4c50-a96f-6a6d029c2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_test_dataset(size=100):\n",
    "\n",
    "    with open('cn-eng-test.txt', 'w+') as f:\n",
    "        f.write('\\n'.join(['\\t'.join(pair) for pair in random.sample(pairs, k=size)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d6f4ed-6f2f-4792-a8ce-59494ca5e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    根据词表，将句子转化成索引列表。\n",
    "\n",
    "    :reutrn list，e.g. [1, 2, 3, 4]\n",
    "    \"\"\"\n",
    "    if lang.name == 'cn':\n",
    "        words = list(jieba.cut(sentence)) if SEGMENTATION else sentence\n",
    "        return [lang.word2index[word] if word in lang.word2index else UNK_token for word in words ]\n",
    "    else:\n",
    "        words = sentence.split(' ')\n",
    "        return [lang.word2index[word] if word in lang.word2index else UNK_token for word in words]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    将句子转换成Tensor.\n",
    "    \n",
    "    :return Tensor, shape(n, 1)\n",
    "    \"\"\"\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = torch.LongTensor(indexes).view(-1, 1)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    \"\"\"\n",
    "    将平行语料对转化成Tensors.\n",
    "    \n",
    "    :return (input_tensor, output_tensor)\n",
    "    \"\"\"\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b15da9-3e26-4895-b391-34c3631d3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair: ['jack是班里最高的男孩。', 'jack is the tallest boy in his class .']\n",
      "input_tensor shape: torch.Size([8, 1]), output_tensor shap: torch.Size([10, 1])\n",
      "input_tensor: tensor([[ 174],\n",
      "        [  26],\n",
      "        [6629],\n",
      "        [5023],\n",
      "        [  47],\n",
      "        [1593],\n",
      "        [  12],\n",
      "        [   1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "print('pair: %s' % pair)\n",
    "\n",
    "input_tensor, target_tensor = variables_from_pair(pair)\n",
    "print('input_tensor shape: %s, output_tensor shap: %s' % (input_tensor.shape, target_tensor.shape))\n",
    "print('input_tensor: %s' % input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb36b5b7-eeca-4814-bf2d-2a55cbd4a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        # 注意：我们一次性处理整个输入序列\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # 初始化隐藏状态和细胞状态\n",
    "        hidden = (torch.zeros(self.n_layers, 1, self.hidden_size),\n",
    "                  torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a14d784-037a-4b90-8f8a-936752887cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    # BahdanauAttention\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W = nn.Linear(hidden_size, hidden_size)\n",
    "        self.U = nn.Linear(hidden_size, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param decoder_hidden: shape(num_layers*num_directions, batch, hidden_size)\n",
    "        :param encoder_outputs: shape(seq_len, batch, num_directions*hidden_size)\n",
    "        :return attention_weighted_encoder_output shape(num_layers, batch, hidden_size)\n",
    "        \"\"\"\n",
    "        query = decoder_hidden[-1]  # 只取decoder最后一层的隐藏状态\n",
    "        query = query.unsqueeze(1)  # 增加维度以便与encoder_outputs相加\n",
    "        energy = torch.tanh(self.W(query) + self.U(encoder_outputs))\n",
    "        attention = F.softmax(self.v(energy), dim=0)\n",
    "        context = attention * encoder_outputs\n",
    "        attn_output = torch.sum(context, dim=0)\n",
    "        return attn_output.view(1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb52b30-aabf-4a4d-8ef7-5460e12d1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    \"\"\"带注意力机制的解码器\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.attention = Attention(hidden_size)\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1)  # S=1 x B x N\n",
    "        \n",
    "        rnn_output, hidden = self.lstm(word_embedded, last_hidden)\n",
    "        rnn_output = rnn_output.squeeze(0)  # squeeze out the time dimension\n",
    "\n",
    "        attn_weighted_encoder_output = self.attention(hidden[0], encoder_outputs)  # 使用LSTM的hidden state\n",
    "        attn_weighted_encoder_output = attn_weighted_encoder_output.squeeze(0)\n",
    "        \n",
    "        concat_output = torch.cat([rnn_output, attn_weighted_encoder_output], dim=1)\n",
    "        output = F.log_softmax(self.out(concat_output), dim=1)\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e057a582-f182-4d7f-b8dc-f962d25098b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, \n",
    "          encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = torch.LongTensor([[SOS_token]])\n",
    "    # Use last hidden state from encoder to start decoder\n",
    "    decoder_hidden = encoder_hidden\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = torch.LongTensor([[ni]]) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9041dcb-c3b2-4794-a2bb-bcb01579c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8e52d9d-08cc-4909-82fd-d2385eeeab25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/tmp/ipykernel_4122/3644649550.py:57: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
      "/tmp/ipykernel_4122/3644649550.py:58: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/150000, 0m 15s (- 37m 41s), 4.9169\n",
      "Epoch 2000/150000, 0m 30s (- 38m 9s), 4.6386\n",
      "Epoch 3000/150000, 0m 46s (- 38m 22s), 4.4592\n",
      "Epoch 4000/150000, 1m 3s (- 38m 28s), 4.3749\n",
      "Epoch 5000/150000, 1m 19s (- 38m 21s), 4.3224\n",
      "Epoch 6000/150000, 1m 35s (- 38m 8s), 4.2720\n",
      "Epoch 7000/150000, 1m 51s (- 37m 53s), 4.1904\n",
      "Epoch 8000/150000, 2m 7s (- 37m 39s), 4.0752\n",
      "Epoch 9000/150000, 2m 23s (- 37m 24s), 4.0297\n",
      "Epoch 10000/150000, 2m 39s (- 37m 10s), 4.0002\n",
      "Epoch 11000/150000, 2m 55s (- 36m 57s), 3.9343\n",
      "Epoch 12000/150000, 3m 11s (- 36m 46s), 3.9260\n",
      "Epoch 13000/150000, 3m 28s (- 36m 32s), 3.8434\n",
      "Epoch 14000/150000, 3m 44s (- 36m 17s), 3.7957\n",
      "Epoch 15000/150000, 4m 0s (- 36m 3s), 3.7370\n",
      "Epoch 16000/150000, 4m 16s (- 35m 48s), 3.7184\n",
      "Epoch 17000/150000, 4m 32s (- 35m 32s), 3.7138\n",
      "Epoch 18000/150000, 4m 48s (- 35m 17s), 3.6192\n",
      "Epoch 19000/150000, 5m 4s (- 35m 1s), 3.5818\n",
      "Epoch 20000/150000, 5m 21s (- 34m 49s), 3.5513\n",
      "Epoch 21000/150000, 5m 37s (- 34m 35s), 3.5215\n",
      "Epoch 22000/150000, 5m 53s (- 34m 18s), 3.4373\n",
      "Epoch 23000/150000, 6m 10s (- 34m 3s), 3.5138\n",
      "Epoch 24000/150000, 6m 26s (- 33m 46s), 3.4131\n",
      "Epoch 25000/150000, 6m 42s (- 33m 31s), 3.3640\n",
      "Epoch 26000/150000, 6m 58s (- 33m 16s), 3.3901\n",
      "Epoch 27000/150000, 7m 14s (- 33m 0s), 3.2735\n",
      "Epoch 28000/150000, 7m 30s (- 32m 44s), 3.2936\n",
      "Epoch 29000/150000, 7m 47s (- 32m 28s), 3.3351\n",
      "Epoch 30000/150000, 8m 3s (- 32m 12s), 3.3013\n",
      "Epoch 31000/150000, 8m 19s (- 31m 57s), 3.3493\n",
      "Epoch 32000/150000, 8m 35s (- 31m 41s), 3.1991\n",
      "Epoch 33000/150000, 8m 52s (- 31m 26s), 3.2168\n",
      "Epoch 34000/150000, 9m 8s (- 31m 11s), 3.1579\n",
      "Epoch 35000/150000, 9m 24s (- 30m 55s), 3.2161\n",
      "Epoch 36000/150000, 9m 40s (- 30m 39s), 3.1349\n",
      "Epoch 37000/150000, 9m 56s (- 30m 23s), 3.1152\n",
      "Epoch 38000/150000, 10m 13s (- 30m 6s), 3.0990\n",
      "Epoch 39000/150000, 10m 29s (- 29m 51s), 3.1493\n",
      "Epoch 40000/150000, 10m 45s (- 29m 35s), 3.1093\n",
      "Epoch 41000/150000, 11m 2s (- 29m 20s), 3.1218\n",
      "Epoch 42000/150000, 11m 18s (- 29m 4s), 2.9202\n",
      "Epoch 43000/150000, 11m 34s (- 28m 48s), 2.9992\n",
      "Epoch 44000/150000, 11m 50s (- 28m 32s), 2.9197\n",
      "Epoch 45000/150000, 12m 7s (- 28m 16s), 2.9635\n",
      "Epoch 46000/150000, 12m 23s (- 28m 0s), 2.9069\n",
      "Epoch 47000/150000, 12m 39s (- 27m 44s), 2.9667\n",
      "Epoch 48000/150000, 12m 55s (- 27m 28s), 2.9045\n",
      "Epoch 49000/150000, 13m 12s (- 27m 12s), 2.9140\n",
      "Epoch 50000/150000, 13m 28s (- 26m 56s), 2.8707\n",
      "Epoch 51000/150000, 13m 44s (- 26m 40s), 2.8075\n",
      "Epoch 52000/150000, 14m 0s (- 26m 24s), 2.8138\n",
      "Epoch 53000/150000, 14m 16s (- 26m 8s), 2.8203\n",
      "Epoch 54000/150000, 14m 33s (- 25m 52s), 2.7501\n",
      "Epoch 55000/150000, 14m 49s (- 25m 36s), 2.8350\n",
      "Epoch 56000/150000, 15m 5s (- 25m 20s), 2.8225\n",
      "Epoch 57000/150000, 15m 22s (- 25m 4s), 2.7535\n",
      "Epoch 58000/150000, 15m 38s (- 24m 48s), 2.7469\n",
      "Epoch 59000/150000, 15m 54s (- 24m 32s), 2.7353\n",
      "Epoch 60000/150000, 16m 11s (- 24m 16s), 2.7188\n",
      "Epoch 61000/150000, 16m 27s (- 24m 0s), 2.6344\n",
      "Epoch 62000/150000, 16m 43s (- 23m 44s), 2.7019\n",
      "Epoch 63000/150000, 17m 0s (- 23m 28s), 2.7541\n",
      "Epoch 64000/150000, 17m 16s (- 23m 12s), 2.7568\n",
      "Epoch 65000/150000, 17m 32s (- 22m 56s), 2.6141\n",
      "Epoch 66000/150000, 17m 48s (- 22m 40s), 2.6502\n",
      "Epoch 67000/150000, 18m 4s (- 22m 23s), 2.5340\n",
      "Epoch 68000/150000, 18m 21s (- 22m 7s), 2.6230\n",
      "Epoch 69000/150000, 18m 37s (- 21m 52s), 2.5949\n",
      "Epoch 70000/150000, 18m 54s (- 21m 36s), 2.6741\n",
      "Epoch 71000/150000, 19m 10s (- 21m 19s), 2.5762\n",
      "Epoch 72000/150000, 19m 26s (- 21m 3s), 2.5678\n",
      "Epoch 73000/150000, 19m 42s (- 20m 47s), 2.5728\n",
      "Epoch 74000/150000, 19m 59s (- 20m 31s), 2.5858\n",
      "Epoch 75000/150000, 20m 15s (- 20m 15s), 2.5333\n",
      "Epoch 76000/150000, 20m 31s (- 19m 59s), 2.4957\n",
      "Epoch 77000/150000, 20m 47s (- 19m 42s), 2.4944\n",
      "Epoch 78000/150000, 21m 4s (- 19m 26s), 2.5177\n",
      "Epoch 79000/150000, 21m 20s (- 19m 10s), 2.4831\n",
      "Epoch 80000/150000, 21m 36s (- 18m 54s), 2.4370\n",
      "Epoch 81000/150000, 21m 53s (- 18m 38s), 2.5318\n",
      "Epoch 82000/150000, 22m 9s (- 18m 22s), 2.4727\n",
      "Epoch 83000/150000, 22m 25s (- 18m 6s), 2.4775\n",
      "Epoch 84000/150000, 22m 42s (- 17m 50s), 2.5222\n",
      "Epoch 85000/150000, 22m 58s (- 17m 34s), 2.4129\n",
      "Epoch 86000/150000, 23m 15s (- 17m 18s), 2.4989\n",
      "Epoch 87000/150000, 23m 31s (- 17m 2s), 2.3147\n",
      "Epoch 88000/150000, 23m 47s (- 16m 45s), 2.3818\n",
      "Epoch 89000/150000, 24m 4s (- 16m 29s), 2.3694\n",
      "Epoch 90000/150000, 24m 20s (- 16m 13s), 2.4021\n",
      "Epoch 91000/150000, 24m 36s (- 15m 57s), 2.3017\n",
      "Epoch 92000/150000, 24m 53s (- 15m 41s), 2.2448\n",
      "Epoch 93000/150000, 25m 9s (- 15m 25s), 2.3167\n",
      "Epoch 94000/150000, 25m 26s (- 15m 9s), 2.2935\n",
      "Epoch 95000/150000, 25m 42s (- 14m 53s), 2.3358\n",
      "Epoch 96000/150000, 25m 58s (- 14m 36s), 2.2373\n",
      "Epoch 97000/150000, 26m 14s (- 14m 20s), 2.2217\n",
      "Epoch 98000/150000, 26m 31s (- 14m 4s), 2.2629\n",
      "Epoch 99000/150000, 26m 47s (- 13m 48s), 2.2841\n",
      "Epoch 100000/150000, 27m 4s (- 13m 32s), 2.2408\n",
      "Epoch 101000/150000, 27m 20s (- 13m 15s), 2.1526\n",
      "Epoch 102000/150000, 27m 37s (- 12m 59s), 2.2589\n",
      "Epoch 103000/150000, 27m 53s (- 12m 43s), 2.2017\n",
      "Epoch 104000/150000, 28m 9s (- 12m 27s), 2.2360\n",
      "Epoch 105000/150000, 28m 26s (- 12m 11s), 2.2460\n",
      "Epoch 106000/150000, 28m 42s (- 11m 55s), 2.2050\n",
      "Epoch 107000/150000, 28m 59s (- 11m 38s), 2.1824\n",
      "Epoch 108000/150000, 29m 15s (- 11m 22s), 2.1438\n",
      "Epoch 109000/150000, 29m 32s (- 11m 6s), 2.2594\n",
      "Epoch 110000/150000, 29m 48s (- 10m 50s), 2.1493\n",
      "Epoch 111000/150000, 30m 4s (- 10m 34s), 2.2544\n",
      "Epoch 112000/150000, 30m 21s (- 10m 17s), 2.1450\n",
      "Epoch 113000/150000, 30m 37s (- 10m 1s), 2.1680\n",
      "Epoch 114000/150000, 30m 54s (- 9m 45s), 2.1278\n",
      "Epoch 115000/150000, 31m 10s (- 9m 29s), 2.1552\n",
      "Epoch 116000/150000, 31m 26s (- 9m 13s), 2.1122\n",
      "Epoch 117000/150000, 31m 43s (- 8m 56s), 2.1460\n",
      "Epoch 118000/150000, 31m 59s (- 8m 40s), 2.0553\n",
      "Epoch 119000/150000, 32m 15s (- 8m 24s), 2.0962\n",
      "Epoch 120000/150000, 32m 32s (- 8m 8s), 2.0729\n",
      "Epoch 121000/150000, 32m 48s (- 7m 51s), 2.0977\n",
      "Epoch 122000/150000, 33m 5s (- 7m 35s), 1.9697\n",
      "Epoch 123000/150000, 33m 21s (- 7m 19s), 2.0606\n",
      "Epoch 124000/150000, 33m 38s (- 7m 3s), 2.1235\n",
      "Epoch 125000/150000, 33m 54s (- 6m 46s), 1.9800\n",
      "Epoch 126000/150000, 34m 10s (- 6m 30s), 2.0356\n",
      "Epoch 127000/150000, 34m 27s (- 6m 14s), 2.0054\n",
      "Epoch 128000/150000, 34m 43s (- 5m 58s), 2.0670\n",
      "Epoch 129000/150000, 35m 0s (- 5m 41s), 2.0618\n",
      "Epoch 130000/150000, 35m 16s (- 5m 25s), 2.0167\n",
      "Epoch 131000/150000, 35m 33s (- 5m 9s), 1.9677\n",
      "Epoch 132000/150000, 35m 49s (- 4m 53s), 2.0515\n",
      "Epoch 133000/150000, 36m 6s (- 4m 36s), 1.9667\n",
      "Epoch 134000/150000, 36m 22s (- 4m 20s), 2.0084\n",
      "Epoch 135000/150000, 36m 39s (- 4m 4s), 1.9279\n",
      "Epoch 136000/150000, 36m 55s (- 3m 48s), 1.9922\n",
      "Epoch 137000/150000, 37m 12s (- 3m 31s), 1.8906\n",
      "Epoch 138000/150000, 37m 28s (- 3m 15s), 1.9224\n",
      "Epoch 139000/150000, 37m 45s (- 2m 59s), 2.0674\n",
      "Epoch 140000/150000, 38m 1s (- 2m 42s), 1.9416\n",
      "Epoch 141000/150000, 38m 18s (- 2m 26s), 1.9808\n",
      "Epoch 142000/150000, 38m 34s (- 2m 10s), 1.9546\n",
      "Epoch 143000/150000, 38m 51s (- 1m 54s), 1.9775\n",
      "Epoch 144000/150000, 39m 7s (- 1m 37s), 1.9249\n",
      "Epoch 145000/150000, 39m 23s (- 1m 21s), 1.9514\n",
      "Epoch 146000/150000, 39m 40s (- 1m 5s), 1.8495\n",
      "Epoch 147000/150000, 39m 56s (- 0m 48s), 1.8817\n",
      "Epoch 148000/150000, 40m 13s (- 0m 32s), 1.9476\n",
      "Epoch 149000/150000, 40m 29s (- 0m 16s), 1.9241\n",
      "Epoch 150000/150000, 40m 46s (- 0m 0s), 1.8725\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 500\n",
    "n_layers = 1\n",
    "dropout_p = 0.05\n",
    "n_epochs = 150000\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderLSTM(input_lang.n_words, hidden_size, n_layers)\n",
    "decoder = DecoderLSTM(hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Configuring training\n",
    "plot_every = 200\n",
    "print_every = 1000\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every\n",
    "\n",
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, \n",
    "                 encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = 'Epoch %d/%d, %s, %.4f' % (epoch, n_epochs, time_since(start, epoch / n_epochs), \n",
    "                                                   print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55dad5a4-ae25-41c0-ad69-09b4dfcdceaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6326a085-969f-48ff-bf75-407c4501310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = torch.LongTensor([[SOS_token]]) # SOS\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni.item()])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = torch.LongTensor([[ni]])\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3024e586-db16-453b-801e-12feaf930e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e45951d4-b509-4b90-9663-22b334a805f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 反动派被人民所推翻。\n",
      "= reactionary groups were overthrown by the people .\n",
      "< the people were were by the the . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0c5f418-1426-48b7-85fc-a387f563e7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'life is fun . <EOS>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(evaluate('人生是有趣的。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a2bdac9-5e5e-49e6-9ab4-0322b605b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "\n",
    "# 读取测试数据集\n",
    "with open('cn-eng-test.txt') as f:\n",
    "    lines = f.read().strip().split('\\n')\n",
    "    \n",
    "    test_pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "\n",
    "\n",
    "test_pairs_dict = collections.defaultdict(lambda : [])\n",
    "\n",
    "for pair in test_pairs:\n",
    "    test_pairs_dict[pair[0]].append(pair[1].split(' '))\n",
    "\n",
    "\n",
    "def evaluate_bleu_score():\n",
    "    candicates = []\n",
    "    references = []\n",
    "\n",
    "    for i, pair in enumerate(test_pairs_dict.items(), start=1):\n",
    "        candicate = evaluate(pair[0])\n",
    "        if candicate[-1] == '<EOS>':\n",
    "            candicate.pop(-1)\n",
    "        candicates.append(candicate)\n",
    "        references.append(pair[1])\n",
    "    \n",
    "    score = bleu_score(candicates, references)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ceb9ede-06be-495e-87f6-300e610b6504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset bleu score: 0.393245084918126\n"
     ]
    }
   ],
   "source": [
    "print('test dataset bleu score: %s' % evaluate_bleu_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "409fa2af-05fd-4c9e-8ba8-7dd7ac230234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filepath):\n",
    "    \"\"\"预测\"\"\"\n",
    "    with open('test.txt') as f:\n",
    "        sentences =  [line.strip() for line in f.readlines()]\n",
    "\n",
    "    output_sentences = []\n",
    "    for sentence in sentences:\n",
    "        output_sentence = ' '.join(evaluate(sentence))\n",
    "        output_sentences.append(output_sentence.strip('<EOS>'))\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write('\\n'.join(output_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db6af12-1d84-454e-be62-47fc58069528",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('result-attention.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd9011-7c3d-43f7-bc3b-4a6cc4c7c5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9e89d-3f36-48c2-b340-d4d585e3f442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4801d-0d5c-4b79-b13f-5afd1f022ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa31519-5c58-441c-aa24-011db7f33991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdddd0-0a46-41d0-bb1a-2b23543a26a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
