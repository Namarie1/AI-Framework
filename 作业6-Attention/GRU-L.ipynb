{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233cb0f0-d821-40a1-8c2c-304a15d1a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9fc2bf3-95d0-4479-b63f-a83f8d697f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_CUDA: True\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print('USE_CUDA: %s' % USE_CUDA)\n",
    "SEGMENTATION = True    # 是否分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865cc9af-5571-49e0-a98b-2d368eafe65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.!?，。？]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9491f03-ce02-4b33-bd37-f8b1c9a4d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "\n",
    "class Lang(object):\n",
    "    \"\"\"\n",
    "    词表Vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", '2': 'UNK'}\n",
    "        self.n_words = 3 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        if self.name == 'cn':\n",
    "            words = list(jieba.cut(sentence)) if SEGMENTATION else sentence    \n",
    "            for word in words:\n",
    "                self.index_word(word)\n",
    "        else:\n",
    "            words = sentence.split(' ')\n",
    "            for word in words:\n",
    "                self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4081ee41-9fce-45db-8b90-8e0f33ec1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('%s-%s.txt' % (lang1, lang2)).read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04305de-f262-4d44-b491-1f4dc6349a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79122520-a762-4e9e-8f74-5f78954d242f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 90000 sentence pairs\n",
      "Trimmed to 68898 sentence pairs\n",
      "Indexing words...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.601 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我相信你。', 'i believe you .']\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('cn', 'eng', False)\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dce8645-4ce5-4c50-a96f-6a6d029c2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_test_dataset(size=100):\n",
    "\n",
    "    with open('cn-eng-test.txt', 'w+') as f:\n",
    "        f.write('\\n'.join(['\\t'.join(pair) for pair in random.sample(pairs, k=size)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d6f4ed-6f2f-4792-a8ce-59494ca5e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    根据词表，将句子转化成索引列表。\n",
    "\n",
    "    :reutrn list，e.g. [1, 2, 3, 4]\n",
    "    \"\"\"\n",
    "    if lang.name == 'cn':\n",
    "        words = list(jieba.cut(sentence)) if SEGMENTATION else sentence\n",
    "        return [lang.word2index[word] if word in lang.word2index else UNK_token for word in words ]\n",
    "    else:\n",
    "        words = sentence.split(' ')\n",
    "        return [lang.word2index[word] if word in lang.word2index else UNK_token for word in words]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    将句子转换成Tensor.\n",
    "    \n",
    "    :return Tensor, shape(n, 1)\n",
    "    \"\"\"\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = torch.LongTensor(indexes).view(-1, 1)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    \"\"\"\n",
    "    将平行语料对转化成Tensors.\n",
    "    \n",
    "    :return (input_tensor, output_tensor)\n",
    "    \"\"\"\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b15da9-3e26-4895-b391-34c3631d3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair: ['三個月后，湯姆死了。', 'three months later tom was dead .']\n",
      "input_tensor shape: torch.Size([8, 1]), output_tensor shap: torch.Size([8, 1])\n",
      "input_tensor: tensor([[ 6753],\n",
      "        [  757],\n",
      "        [ 2839],\n",
      "        [   21],\n",
      "        [16436],\n",
      "        [   11],\n",
      "        [   12],\n",
      "        [    1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "print('pair: %s' % pair)\n",
    "\n",
    "input_tensor, target_tensor = variables_from_pair(pair)\n",
    "print('input_tensor shape: %s, output_tensor shap: %s' % (input_tensor.shape, target_tensor.shape))\n",
    "print('input_tensor: %s' % input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb36b5b7-eeca-4814-bf2d-2a55cbd4a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderGRU(nn.Module):\n",
    "    \"\"\"GRU 编码器\"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, bidirectional=False):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param input_size, 输入词表大\n",
    "        :param hidden_size, Embedding维度大小，RNN hidden大小\n",
    "        :param n_layers, RNN层数\n",
    "        \"\"\"\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        # 用GRU替换RNN\n",
    "        # self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param word_inputs, 输入序列 shape(n, 1)\n",
    "        :param hidden, 隐层 shape(seq_len*n_layers, batch_size, hidden_size)\n",
    "        :return output(seq_len, batch, num_directions*hidden_size),\n",
    "                hidden(num_layers*num_directions, hidden_size)\n",
    "        \"\"\"\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        num_directions = 2 if self.bidirectional else 1\n",
    "        hidden = torch.zeros(self.n_layers*num_directions, 1, self.hidden_size)\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a14d784-037a-4b90-8f8a-936752887cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    # LuongAttention\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param decoder_hidden: shape(num_layers*num_directions, batch, hidden_size)\n",
    "        :param encoder_outputs: shape(seq_len, batch, num_directions*hidden_size)\n",
    "        :return attention_weighted_encoder_output shape(num_layers, batch, hidden_size)\n",
    "        \"\"\"\n",
    "        query = decoder_hidden[-1]  # 只取decoder最后一层的隐藏状态\n",
    "        query = query.unsqueeze(0)  # 增加维度以便与encoder_outputs相加\n",
    "        energy = self.W(encoder_outputs)  # Luong attention中的score计算\n",
    "        attention = F.softmax(torch.matmul(query, energy.permute(1, 2, 0)), dim=1)\n",
    "        context = attention.permute(2, 0, 1) * encoder_outputs\n",
    "        attn_output = torch.sum(context, dim=0)\n",
    "        return attn_output.view(1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb52b30-aabf-4a4d-8ef7-5460e12d1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(nn.Module):\n",
    "    \"\"\"注意力机制解码器\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(DecoderGRU, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.attention = Attention(hidden_size)\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "\n",
    "        # 使用GRU替换RNN\n",
    "        # self.rnn = nn.RNN(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size*2, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time        \n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        \n",
    "        rnn_output, hidden = self.rnn(word_embedded, last_hidden)\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "\n",
    "        # attention weighted encoder output\n",
    "        attn_weighted_encoder_output = self.attention(hidden, encoder_outputs)\n",
    "        attn_weighted_encoder_output = attn_weighted_encoder_output.squeeze(0)\n",
    "        \n",
    "        concat_output = torch.cat([rnn_output, attn_weighted_encoder_output], dim=1)\n",
    "        output = F.log_softmax(self.out(concat_output))\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e057a582-f182-4d7f-b8dc-f962d25098b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, \n",
    "          encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = torch.LongTensor([[SOS_token]])\n",
    "    # Use last hidden state from encoder to start decoder\n",
    "    decoder_hidden = encoder_hidden\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = torch.LongTensor([[ni]]) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9041dcb-c3b2-4794-a2bb-bcb01579c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8e52d9d-08cc-4909-82fd-d2385eeeab25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/tmp/ipykernel_2893/3848772925.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.log_softmax(self.out(concat_output))\n",
      "/tmp/ipykernel_2893/3644649550.py:57: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
      "/tmp/ipykernel_2893/3644649550.py:58: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/150000, 0m 20s (- 51m 1s), 4.7820\n",
      "Epoch 2000/150000, 0m 42s (- 52m 10s), 4.3924\n",
      "Epoch 3000/150000, 1m 4s (- 52m 37s), 4.2533\n",
      "Epoch 4000/150000, 1m 26s (- 52m 29s), 4.1053\n",
      "Epoch 5000/150000, 1m 48s (- 52m 19s), 3.9428\n",
      "Epoch 6000/150000, 2m 10s (- 52m 21s), 3.9320\n",
      "Epoch 7000/150000, 2m 33s (- 52m 14s), 3.8456\n",
      "Epoch 8000/150000, 2m 55s (- 52m 2s), 3.7458\n",
      "Epoch 9000/150000, 3m 18s (- 51m 48s), 3.6809\n",
      "Epoch 10000/150000, 3m 40s (- 51m 29s), 3.5966\n",
      "Epoch 11000/150000, 4m 2s (- 51m 10s), 3.5430\n",
      "Epoch 12000/150000, 4m 25s (- 50m 49s), 3.4975\n",
      "Epoch 13000/150000, 4m 47s (- 50m 31s), 3.4589\n",
      "Epoch 14000/150000, 5m 9s (- 50m 8s), 3.3116\n",
      "Epoch 15000/150000, 5m 32s (- 49m 48s), 3.2400\n",
      "Epoch 16000/150000, 5m 54s (- 49m 27s), 3.3390\n",
      "Epoch 17000/150000, 6m 16s (- 49m 9s), 3.2568\n",
      "Epoch 18000/150000, 6m 39s (- 48m 51s), 3.2408\n",
      "Epoch 19000/150000, 7m 2s (- 48m 31s), 3.2270\n",
      "Epoch 20000/150000, 7m 24s (- 48m 11s), 3.2153\n",
      "Epoch 21000/150000, 7m 47s (- 47m 51s), 3.1149\n",
      "Epoch 22000/150000, 8m 9s (- 47m 29s), 3.1408\n",
      "Epoch 23000/150000, 8m 32s (- 47m 8s), 3.0822\n",
      "Epoch 24000/150000, 8m 54s (- 46m 48s), 3.0408\n",
      "Epoch 25000/150000, 9m 17s (- 46m 27s), 3.0419\n",
      "Epoch 26000/150000, 9m 40s (- 46m 8s), 2.9644\n",
      "Epoch 27000/150000, 10m 3s (- 45m 47s), 2.9590\n",
      "Epoch 28000/150000, 10m 25s (- 45m 27s), 3.0050\n",
      "Epoch 29000/150000, 10m 48s (- 45m 6s), 2.8440\n",
      "Epoch 30000/150000, 11m 11s (- 44m 46s), 2.9541\n",
      "Epoch 31000/150000, 11m 34s (- 44m 25s), 2.9294\n",
      "Epoch 32000/150000, 11m 57s (- 44m 5s), 2.8439\n",
      "Epoch 33000/150000, 12m 20s (- 43m 43s), 2.8449\n",
      "Epoch 34000/150000, 12m 42s (- 43m 22s), 2.8406\n",
      "Epoch 35000/150000, 13m 5s (- 43m 0s), 2.6787\n",
      "Epoch 36000/150000, 13m 28s (- 42m 38s), 2.7781\n",
      "Epoch 37000/150000, 13m 50s (- 42m 17s), 2.7693\n",
      "Epoch 38000/150000, 14m 13s (- 41m 55s), 2.7472\n",
      "Epoch 39000/150000, 14m 36s (- 41m 33s), 2.6990\n",
      "Epoch 40000/150000, 14m 58s (- 41m 11s), 2.8103\n",
      "Epoch 41000/150000, 15m 21s (- 40m 50s), 2.6549\n",
      "Epoch 42000/150000, 15m 44s (- 40m 28s), 2.6583\n",
      "Epoch 43000/150000, 16m 6s (- 40m 6s), 2.5757\n",
      "Epoch 44000/150000, 16m 29s (- 39m 44s), 2.6312\n",
      "Epoch 45000/150000, 16m 52s (- 39m 22s), 2.6376\n",
      "Epoch 46000/150000, 17m 15s (- 39m 0s), 2.6521\n",
      "Epoch 47000/150000, 17m 38s (- 38m 39s), 2.6318\n",
      "Epoch 48000/150000, 18m 1s (- 38m 17s), 2.6256\n",
      "Epoch 49000/150000, 18m 23s (- 37m 55s), 2.5418\n",
      "Epoch 50000/150000, 18m 46s (- 37m 33s), 2.5462\n",
      "Epoch 51000/150000, 19m 9s (- 37m 11s), 2.5632\n",
      "Epoch 52000/150000, 19m 32s (- 36m 49s), 2.5392\n",
      "Epoch 53000/150000, 19m 55s (- 36m 27s), 2.5154\n",
      "Epoch 54000/150000, 20m 18s (- 36m 5s), 2.4616\n",
      "Epoch 55000/150000, 20m 40s (- 35m 43s), 2.5334\n",
      "Epoch 56000/150000, 21m 3s (- 35m 21s), 2.5223\n",
      "Epoch 57000/150000, 21m 26s (- 34m 59s), 2.4885\n",
      "Epoch 58000/150000, 21m 49s (- 34m 36s), 2.4591\n",
      "Epoch 59000/150000, 22m 12s (- 34m 14s), 2.4317\n",
      "Epoch 60000/150000, 22m 35s (- 33m 52s), 2.4310\n",
      "Epoch 61000/150000, 22m 58s (- 33m 30s), 2.3805\n",
      "Epoch 62000/150000, 23m 20s (- 33m 7s), 2.4385\n",
      "Epoch 63000/150000, 23m 43s (- 32m 45s), 2.4500\n",
      "Epoch 64000/150000, 24m 5s (- 32m 23s), 2.3974\n",
      "Epoch 65000/150000, 24m 28s (- 32m 0s), 2.3902\n",
      "Epoch 66000/150000, 24m 51s (- 31m 38s), 2.3887\n",
      "Epoch 67000/150000, 25m 14s (- 31m 16s), 2.4101\n",
      "Epoch 68000/150000, 25m 37s (- 30m 54s), 2.4185\n",
      "Epoch 69000/150000, 26m 0s (- 30m 31s), 2.3057\n",
      "Epoch 70000/150000, 26m 23s (- 30m 9s), 2.3433\n",
      "Epoch 71000/150000, 26m 46s (- 29m 47s), 2.4269\n",
      "Epoch 72000/150000, 27m 8s (- 29m 24s), 2.2761\n",
      "Epoch 73000/150000, 27m 31s (- 29m 2s), 2.3026\n",
      "Epoch 74000/150000, 27m 54s (- 28m 39s), 2.3086\n",
      "Epoch 75000/150000, 28m 17s (- 28m 17s), 2.2897\n",
      "Epoch 76000/150000, 28m 40s (- 27m 55s), 2.3004\n",
      "Epoch 77000/150000, 29m 3s (- 27m 33s), 2.2661\n",
      "Epoch 78000/150000, 29m 26s (- 27m 10s), 2.2683\n",
      "Epoch 79000/150000, 29m 49s (- 26m 48s), 2.2535\n",
      "Epoch 80000/150000, 30m 12s (- 26m 26s), 2.2414\n",
      "Epoch 81000/150000, 30m 35s (- 26m 3s), 2.1843\n",
      "Epoch 82000/150000, 30m 58s (- 25m 41s), 2.1813\n",
      "Epoch 83000/150000, 31m 21s (- 25m 19s), 2.1486\n",
      "Epoch 84000/150000, 31m 44s (- 24m 56s), 2.2040\n",
      "Epoch 85000/150000, 32m 8s (- 24m 34s), 2.2759\n",
      "Epoch 86000/150000, 32m 30s (- 24m 11s), 2.1526\n",
      "Epoch 87000/150000, 32m 53s (- 23m 49s), 2.1883\n",
      "Epoch 88000/150000, 33m 16s (- 23m 26s), 2.1183\n",
      "Epoch 89000/150000, 33m 38s (- 23m 3s), 2.1383\n",
      "Epoch 90000/150000, 34m 1s (- 22m 41s), 2.1975\n",
      "Epoch 91000/150000, 34m 24s (- 22m 18s), 2.1371\n",
      "Epoch 92000/150000, 34m 47s (- 21m 55s), 2.1032\n",
      "Epoch 93000/150000, 35m 10s (- 21m 33s), 2.1168\n",
      "Epoch 94000/150000, 35m 33s (- 21m 10s), 2.0954\n",
      "Epoch 95000/150000, 35m 55s (- 20m 47s), 2.0356\n",
      "Epoch 96000/150000, 36m 18s (- 20m 25s), 2.1524\n",
      "Epoch 97000/150000, 36m 41s (- 20m 2s), 2.1001\n",
      "Epoch 98000/150000, 37m 4s (- 19m 40s), 2.1521\n",
      "Epoch 99000/150000, 37m 27s (- 19m 17s), 2.0855\n",
      "Epoch 100000/150000, 37m 50s (- 18m 55s), 2.0609\n",
      "Epoch 101000/150000, 38m 14s (- 18m 33s), 2.0286\n",
      "Epoch 102000/150000, 38m 37s (- 18m 10s), 2.1067\n",
      "Epoch 103000/150000, 39m 0s (- 17m 47s), 2.0018\n",
      "Epoch 104000/150000, 39m 23s (- 17m 25s), 1.9757\n",
      "Epoch 105000/150000, 39m 46s (- 17m 2s), 2.0677\n",
      "Epoch 106000/150000, 40m 9s (- 16m 40s), 2.0026\n",
      "Epoch 107000/150000, 40m 32s (- 16m 17s), 2.1276\n",
      "Epoch 108000/150000, 40m 55s (- 15m 55s), 1.9599\n",
      "Epoch 109000/150000, 41m 18s (- 15m 32s), 1.9509\n",
      "Epoch 110000/150000, 41m 41s (- 15m 9s), 1.9787\n",
      "Epoch 111000/150000, 42m 4s (- 14m 47s), 2.0808\n",
      "Epoch 112000/150000, 42m 27s (- 14m 24s), 1.9733\n",
      "Epoch 113000/150000, 42m 50s (- 14m 1s), 1.9481\n",
      "Epoch 114000/150000, 43m 13s (- 13m 39s), 2.0291\n",
      "Epoch 115000/150000, 43m 36s (- 13m 16s), 1.9323\n",
      "Epoch 116000/150000, 43m 59s (- 12m 53s), 1.9361\n",
      "Epoch 117000/150000, 44m 22s (- 12m 30s), 2.0038\n",
      "Epoch 118000/150000, 44m 45s (- 12m 8s), 1.9354\n",
      "Epoch 119000/150000, 45m 8s (- 11m 45s), 1.8538\n",
      "Epoch 120000/150000, 45m 31s (- 11m 22s), 1.9529\n",
      "Epoch 121000/150000, 45m 54s (- 11m 0s), 1.9890\n",
      "Epoch 122000/150000, 46m 18s (- 10m 37s), 2.0023\n",
      "Epoch 123000/150000, 46m 41s (- 10m 14s), 1.9407\n",
      "Epoch 124000/150000, 47m 4s (- 9m 52s), 1.9016\n",
      "Epoch 125000/150000, 47m 27s (- 9m 29s), 1.8359\n",
      "Epoch 126000/150000, 47m 50s (- 9m 6s), 1.9215\n",
      "Epoch 127000/150000, 48m 13s (- 8m 44s), 1.8320\n",
      "Epoch 128000/150000, 48m 36s (- 8m 21s), 1.8734\n",
      "Epoch 129000/150000, 48m 58s (- 7m 58s), 1.9488\n",
      "Epoch 130000/150000, 49m 21s (- 7m 35s), 1.9589\n",
      "Epoch 131000/150000, 49m 44s (- 7m 12s), 1.9535\n",
      "Epoch 132000/150000, 50m 8s (- 6m 50s), 1.8357\n",
      "Epoch 133000/150000, 50m 31s (- 6m 27s), 1.8649\n",
      "Epoch 134000/150000, 50m 54s (- 6m 4s), 1.8053\n",
      "Epoch 135000/150000, 51m 17s (- 5m 41s), 1.8741\n",
      "Epoch 136000/150000, 51m 40s (- 5m 19s), 1.8114\n",
      "Epoch 137000/150000, 52m 3s (- 4m 56s), 1.7909\n",
      "Epoch 138000/150000, 52m 26s (- 4m 33s), 1.7783\n",
      "Epoch 139000/150000, 52m 49s (- 4m 10s), 1.7696\n",
      "Epoch 140000/150000, 53m 12s (- 3m 48s), 1.8057\n",
      "Epoch 141000/150000, 53m 35s (- 3m 25s), 1.7335\n",
      "Epoch 142000/150000, 53m 58s (- 3m 2s), 1.8173\n",
      "Epoch 143000/150000, 54m 22s (- 2m 39s), 1.8535\n",
      "Epoch 144000/150000, 54m 44s (- 2m 16s), 1.7667\n",
      "Epoch 145000/150000, 55m 7s (- 1m 54s), 1.8032\n",
      "Epoch 146000/150000, 55m 31s (- 1m 31s), 1.7802\n",
      "Epoch 147000/150000, 55m 53s (- 1m 8s), 1.7460\n",
      "Epoch 148000/150000, 56m 16s (- 0m 45s), 1.7615\n",
      "Epoch 149000/150000, 56m 39s (- 0m 22s), 1.7480\n",
      "Epoch 150000/150000, 57m 3s (- 0m 0s), 1.8252\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 500\n",
    "n_layers = 1\n",
    "dropout_p = 0.05\n",
    "n_epochs = 150000\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderGRU(input_lang.n_words, hidden_size, n_layers)\n",
    "decoder = DecoderGRU(hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Configuring training\n",
    "plot_every = 200\n",
    "print_every = 1000\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every\n",
    "\n",
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, \n",
    "                 encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = 'Epoch %d/%d, %s, %.4f' % (epoch, n_epochs, time_since(start, epoch / n_epochs), \n",
    "                                                   print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55dad5a4-ae25-41c0-ad69-09b4dfcdceaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6326a085-969f-48ff-bf75-407c4501310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = torch.LongTensor([[SOS_token]]) # SOS\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni.item()])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = torch.LongTensor([[ni]])\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3024e586-db16-453b-801e-12feaf930e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e45951d4-b509-4b90-9663-22b334a805f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 电视正在播足球赛。\n",
      "= the football game is now on the air .\n",
      "< the football game is on the the . . <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2893/3848772925.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.log_softmax(self.out(concat_output))\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0c5f418-1426-48b7-85fc-a387f563e7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2893/3848772925.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.log_softmax(self.out(concat_output))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'life is fun . <EOS>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(evaluate('人生是有趣的。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a2bdac9-5e5e-49e6-9ab4-0322b605b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "\n",
    "# 读取测试数据集\n",
    "with open('cn-eng-test.txt') as f:\n",
    "    lines = f.read().strip().split('\\n')\n",
    "    \n",
    "    test_pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "\n",
    "\n",
    "test_pairs_dict = collections.defaultdict(lambda : [])\n",
    "\n",
    "for pair in test_pairs:\n",
    "    test_pairs_dict[pair[0]].append(pair[1].split(' '))\n",
    "\n",
    "\n",
    "def evaluate_bleu_score():\n",
    "    candicates = []\n",
    "    references = []\n",
    "\n",
    "    for i, pair in enumerate(test_pairs_dict.items(), start=1):\n",
    "        candicate = evaluate(pair[0])\n",
    "        if candicate[-1] == '<EOS>':\n",
    "            candicate.pop(-1)\n",
    "        candicates.append(candicate)\n",
    "        references.append(pair[1])\n",
    "    \n",
    "    score = bleu_score(candicates, references)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ceb9ede-06be-495e-87f6-300e610b6504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2893/3848772925.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.log_softmax(self.out(concat_output))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset bleu score: 0.3307007538766883\n"
     ]
    }
   ],
   "source": [
    "print('test dataset bleu score: %s' % evaluate_bleu_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "409fa2af-05fd-4c9e-8ba8-7dd7ac230234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filepath):\n",
    "    \"\"\"预测\"\"\"\n",
    "    with open('test.txt') as f:\n",
    "        sentences =  [line.strip() for line in f.readlines()]\n",
    "\n",
    "    output_sentences = []\n",
    "    for sentence in sentences:\n",
    "        output_sentence = ' '.join(evaluate(sentence))\n",
    "        output_sentences.append(output_sentence.strip('<EOS>'))\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write('\\n'.join(output_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db6af12-1d84-454e-be62-47fc58069528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2893/3848772925.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.log_softmax(self.out(concat_output))\n"
     ]
    }
   ],
   "source": [
    "predict('result-attention.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd9011-7c3d-43f7-bc3b-4a6cc4c7c5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9e89d-3f36-48c2-b340-d4d585e3f442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4801d-0d5c-4b79-b13f-5afd1f022ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa31519-5c58-441c-aa24-011db7f33991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdddd0-0a46-41d0-bb1a-2b23543a26a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
