{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233cb0f0-d821-40a1-8c2c-304a15d1a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9fc2bf3-95d0-4479-b63f-a83f8d697f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_CUDA: True\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print('USE_CUDA: %s' % USE_CUDA)\n",
    "SEGMENTATION = True    # 是否分词\n",
    "\n",
    "\n",
    "# 检查 CUDA 是否可用\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available. Please check your CUDA and cuDNN installation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865cc9af-5571-49e0-a98b-2d368eafe65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z\\u4e00-\\u9fa5.!?，。？]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9491f03-ce02-4b33-bd37-f8b1c9a4d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "\n",
    "class Lang(object):\n",
    "    \"\"\"\n",
    "    词表Vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", '2': 'UNK'}\n",
    "        self.n_words = 3 # Count SOS and EOS\n",
    "      \n",
    "    def index_words(self, sentence):\n",
    "        if self.name == 'cn':\n",
    "            words = list(jieba.cut(sentence)) if SEGMENTATION else sentence    \n",
    "            for word in words:\n",
    "                self.index_word(word)\n",
    "        else:\n",
    "            words = sentence.split(' ')\n",
    "            for word in words:\n",
    "                self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4081ee41-9fce-45db-8b90-8e0f33ec1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('%s-%s.txt' % (lang1, lang2)).read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04305de-f262-4d44-b491-1f4dc6349a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def filter_pair(p):\n",
    "    return len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    return [pair for pair in pairs if filter_pair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79122520-a762-4e9e-8f74-5f78954d242f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 90000 sentence pairs\n",
      "Trimmed to 68898 sentence pairs\n",
      "Indexing words...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.588 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['今天上午下雨。', 'it will rain this morning .']\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('cn', 'eng', False)\n",
    "\n",
    "# Print an example pair\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dce8645-4ce5-4c50-a96f-6a6d029c2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_test_dataset(size=100):\n",
    "\n",
    "    with open('cn-eng-test.txt', 'w+') as f:\n",
    "        f.write('\\n'.join(['\\t'.join(pair) for pair in random.sample(pairs, k=size)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d6f4ed-6f2f-4792-a8ce-59494ca5e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    根据词表，将句子转化成索引列表。\n",
    "\n",
    "    :reutrn list，e.g. [1, 2, 3, 4]\n",
    "    \"\"\"\n",
    "    if lang.name == 'cn':\n",
    "        words = list(jieba.cut(sentence)) if SEGMENTATION else sentence\n",
    "        return [lang.word2index[word] if word in lang.word2index else UNK_token for word in words ]\n",
    "    else:\n",
    "        words = sentence.split(' ')\n",
    "        return [lang.word2index[word] if word in lang.word2index else UNK_token for word in words]\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    将句子转换成Tensor.\n",
    "    \n",
    "    :return Tensor, shape(n, 1)\n",
    "    \"\"\"\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = torch.LongTensor(indexes).view(-1, 1)\n",
    "    if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    \"\"\"\n",
    "    将平行语料对转化成Tensors.\n",
    "    \n",
    "    :return (input_tensor, output_tensor)\n",
    "    \"\"\"\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b15da9-3e26-4895-b391-34c3631d3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair: ['我喜歡你笑得樣子。', 'i like your way of smiling .']\n",
      "input_tensor shape: torch.Size([8, 1]), output_tensor shap: torch.Size([8, 1])\n",
      "input_tensor: tensor([[   7],\n",
      "        [  79],\n",
      "        [  13],\n",
      "        [ 783],\n",
      "        [ 113],\n",
      "        [1432],\n",
      "        [  12],\n",
      "        [   1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "print('pair: %s' % pair)\n",
    "\n",
    "input_tensor, target_tensor = variables_from_pair(pair)\n",
    "print('input_tensor shape: %s, output_tensor shap: %s' % (input_tensor.shape, target_tensor.shape))\n",
    "print('input_tensor: %s' % input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb36b5b7-eeca-4814-bf2d-2a55cbd4a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        # 注意：我们一次性处理整个输入序列\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # 初始化隐藏状态和细胞状态\n",
    "        hidden = (torch.zeros(self.n_layers, 1, self.hidden_size),\n",
    "                  torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a14d784-037a-4b90-8f8a-936752887cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    # LuongAttention\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param decoder_hidden: shape(num_layers*num_directions, batch, hidden_size)\n",
    "        :param encoder_outputs: shape(seq_len, batch, num_directions*hidden_size)\n",
    "        :return attention_weighted_encoder_output shape(num_layers, batch, hidden_size)\n",
    "        \"\"\"\n",
    "        query = decoder_hidden[-1]  # 只取decoder最后一层的隐藏状态\n",
    "        query = query.unsqueeze(0)  # 增加维度以便与encoder_outputs相加\n",
    "        energy = self.W(encoder_outputs)  # Luong attention中的score计算\n",
    "        attention = F.softmax(torch.matmul(query, energy.permute(1, 2, 0)), dim=1)\n",
    "        context = attention.permute(2, 0, 1) * encoder_outputs\n",
    "        attn_output = torch.sum(context, dim=0)\n",
    "        return attn_output.view(1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb52b30-aabf-4a4d-8ef7-5460e12d1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    \"\"\"带注意力机制的解码器\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.attention = Attention(hidden_size)\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1)  # S=1 x B x N\n",
    "        \n",
    "        rnn_output, hidden = self.lstm(word_embedded, last_hidden)\n",
    "        rnn_output = rnn_output.squeeze(0)  # squeeze out the time dimension\n",
    "\n",
    "        attn_weighted_encoder_output = self.attention(hidden[0], encoder_outputs)  # 使用LSTM的hidden state\n",
    "        attn_weighted_encoder_output = attn_weighted_encoder_output.squeeze(0)\n",
    "        \n",
    "        concat_output = torch.cat([rnn_output, attn_weighted_encoder_output], dim=1)\n",
    "        output = F.log_softmax(self.out(concat_output), dim=1)\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e057a582-f182-4d7f-b8dc-f962d25098b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, \n",
    "          encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = torch.LongTensor([[SOS_token]])\n",
    "    # Use last hidden state from encoder to start decoder\n",
    "    decoder_hidden = encoder_hidden\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = torch.LongTensor([[ni]]) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == EOS_token: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9041dcb-c3b2-4794-a2bb-bcb01579c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8e52d9d-08cc-4909-82fd-d2385eeeab25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/tmp/ipykernel_868/3644649550.py:57: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
      "/tmp/ipykernel_868/3644649550.py:58: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/150000, 0m 14s (- 35m 55s), 4.7749\n",
      "Epoch 2000/150000, 0m 29s (- 36m 1s), 4.5499\n",
      "Epoch 3000/150000, 0m 43s (- 35m 40s), 4.3703\n",
      "Epoch 4000/150000, 0m 58s (- 35m 27s), 4.2461\n",
      "Epoch 5000/150000, 1m 13s (- 35m 20s), 4.1549\n",
      "Epoch 6000/150000, 1m 28s (- 35m 12s), 3.9911\n",
      "Epoch 7000/150000, 1m 42s (- 34m 57s), 3.9299\n",
      "Epoch 8000/150000, 1m 57s (- 34m 42s), 3.8544\n",
      "Epoch 9000/150000, 2m 12s (- 34m 38s), 3.8328\n",
      "Epoch 10000/150000, 2m 27s (- 34m 29s), 3.6954\n",
      "Epoch 11000/150000, 2m 42s (- 34m 13s), 3.6130\n",
      "Epoch 12000/150000, 2m 57s (- 33m 57s), 3.5777\n",
      "Epoch 13000/150000, 3m 11s (- 33m 41s), 3.5788\n",
      "Epoch 14000/150000, 3m 26s (- 33m 28s), 3.4770\n",
      "Epoch 15000/150000, 3m 41s (- 33m 14s), 3.4531\n",
      "Epoch 16000/150000, 3m 56s (- 33m 0s), 3.4618\n",
      "Epoch 17000/150000, 4m 11s (- 32m 48s), 3.4474\n",
      "Epoch 18000/150000, 4m 28s (- 32m 49s), 3.3323\n",
      "Epoch 19000/150000, 4m 44s (- 32m 38s), 3.2603\n",
      "Epoch 20000/150000, 4m 59s (- 32m 26s), 3.2181\n",
      "Epoch 21000/150000, 5m 15s (- 32m 16s), 3.2496\n",
      "Epoch 22000/150000, 5m 30s (- 32m 3s), 3.1352\n",
      "Epoch 23000/150000, 5m 45s (- 31m 48s), 3.2544\n",
      "Epoch 24000/150000, 6m 0s (- 31m 34s), 3.1147\n",
      "Epoch 25000/150000, 6m 16s (- 31m 22s), 3.0117\n",
      "Epoch 26000/150000, 6m 31s (- 31m 8s), 3.1170\n",
      "Epoch 27000/150000, 6m 47s (- 30m 54s), 3.0540\n",
      "Epoch 28000/150000, 7m 2s (- 30m 39s), 2.9727\n",
      "Epoch 29000/150000, 7m 17s (- 30m 25s), 2.9683\n",
      "Epoch 30000/150000, 7m 32s (- 30m 11s), 2.9232\n",
      "Epoch 31000/150000, 7m 47s (- 29m 55s), 2.9898\n",
      "Epoch 32000/150000, 8m 2s (- 29m 40s), 2.9231\n",
      "Epoch 33000/150000, 8m 18s (- 29m 26s), 2.8890\n",
      "Epoch 34000/150000, 8m 33s (- 29m 11s), 2.8556\n",
      "Epoch 35000/150000, 8m 48s (- 28m 56s), 2.9299\n",
      "Epoch 36000/150000, 9m 3s (- 28m 41s), 2.8609\n",
      "Epoch 37000/150000, 9m 18s (- 28m 27s), 2.8531\n",
      "Epoch 38000/150000, 9m 34s (- 28m 12s), 2.8283\n",
      "Epoch 39000/150000, 9m 49s (- 27m 58s), 2.7717\n",
      "Epoch 40000/150000, 10m 5s (- 27m 43s), 2.6903\n",
      "Epoch 41000/150000, 10m 20s (- 27m 28s), 2.7507\n",
      "Epoch 42000/150000, 10m 35s (- 27m 13s), 2.7279\n",
      "Epoch 43000/150000, 10m 50s (- 26m 59s), 2.6645\n",
      "Epoch 44000/150000, 11m 5s (- 26m 44s), 2.6870\n",
      "Epoch 45000/150000, 11m 21s (- 26m 29s), 2.6616\n",
      "Epoch 46000/150000, 11m 36s (- 26m 14s), 2.6225\n",
      "Epoch 47000/150000, 11m 51s (- 25m 59s), 2.6930\n",
      "Epoch 48000/150000, 12m 6s (- 25m 44s), 2.6471\n",
      "Epoch 49000/150000, 12m 21s (- 25m 29s), 2.6112\n",
      "Epoch 50000/150000, 12m 36s (- 25m 13s), 2.5530\n",
      "Epoch 51000/150000, 12m 51s (- 24m 58s), 2.6039\n",
      "Epoch 52000/150000, 13m 7s (- 24m 43s), 2.5554\n",
      "Epoch 53000/150000, 13m 22s (- 24m 28s), 2.5659\n",
      "Epoch 54000/150000, 13m 37s (- 24m 13s), 2.4922\n",
      "Epoch 55000/150000, 13m 53s (- 23m 58s), 2.4694\n",
      "Epoch 56000/150000, 14m 8s (- 23m 44s), 2.5595\n",
      "Epoch 57000/150000, 14m 23s (- 23m 29s), 2.4758\n",
      "Epoch 58000/150000, 14m 38s (- 23m 14s), 2.4807\n",
      "Epoch 59000/150000, 14m 54s (- 22m 59s), 2.4708\n",
      "Epoch 60000/150000, 15m 9s (- 22m 44s), 2.4664\n",
      "Epoch 61000/150000, 15m 24s (- 22m 28s), 2.3861\n",
      "Epoch 62000/150000, 15m 39s (- 22m 14s), 2.4604\n",
      "Epoch 63000/150000, 15m 54s (- 21m 58s), 2.4180\n",
      "Epoch 64000/150000, 16m 10s (- 21m 43s), 2.4883\n",
      "Epoch 65000/150000, 16m 25s (- 21m 28s), 2.3246\n",
      "Epoch 66000/150000, 16m 40s (- 21m 13s), 2.4315\n",
      "Epoch 67000/150000, 16m 55s (- 20m 58s), 2.3780\n",
      "Epoch 68000/150000, 17m 11s (- 20m 43s), 2.4073\n",
      "Epoch 69000/150000, 17m 26s (- 20m 28s), 2.2934\n",
      "Epoch 70000/150000, 17m 41s (- 20m 13s), 2.3930\n",
      "Epoch 71000/150000, 17m 56s (- 19m 57s), 2.3503\n",
      "Epoch 72000/150000, 18m 11s (- 19m 42s), 2.3323\n",
      "Epoch 73000/150000, 18m 27s (- 19m 27s), 2.2732\n",
      "Epoch 74000/150000, 18m 42s (- 19m 12s), 2.2339\n",
      "Epoch 75000/150000, 18m 57s (- 18m 57s), 2.2793\n",
      "Epoch 76000/150000, 19m 12s (- 18m 42s), 2.2818\n",
      "Epoch 77000/150000, 19m 29s (- 18m 28s), 2.2216\n",
      "Epoch 78000/150000, 19m 44s (- 18m 13s), 2.2561\n",
      "Epoch 79000/150000, 19m 59s (- 17m 58s), 2.2201\n",
      "Epoch 80000/150000, 20m 15s (- 17m 43s), 2.1591\n",
      "Epoch 81000/150000, 20m 30s (- 17m 27s), 2.2015\n",
      "Epoch 82000/150000, 20m 45s (- 17m 12s), 2.2225\n",
      "Epoch 83000/150000, 21m 0s (- 16m 57s), 2.1917\n",
      "Epoch 84000/150000, 21m 15s (- 16m 42s), 2.1767\n",
      "Epoch 85000/150000, 21m 31s (- 16m 27s), 2.2140\n",
      "Epoch 86000/150000, 21m 46s (- 16m 12s), 2.1709\n",
      "Epoch 87000/150000, 22m 1s (- 15m 57s), 2.1589\n",
      "Epoch 88000/150000, 22m 17s (- 15m 41s), 2.1572\n",
      "Epoch 89000/150000, 22m 32s (- 15m 26s), 2.1418\n",
      "Epoch 90000/150000, 22m 47s (- 15m 11s), 2.1920\n",
      "Epoch 91000/150000, 23m 3s (- 14m 56s), 2.1471\n",
      "Epoch 92000/150000, 23m 18s (- 14m 41s), 2.2288\n",
      "Epoch 93000/150000, 23m 33s (- 14m 26s), 2.0655\n",
      "Epoch 94000/150000, 23m 48s (- 14m 11s), 2.1396\n",
      "Epoch 95000/150000, 24m 4s (- 13m 56s), 2.0809\n",
      "Epoch 96000/150000, 24m 19s (- 13m 40s), 2.0344\n",
      "Epoch 97000/150000, 24m 34s (- 13m 25s), 2.0723\n",
      "Epoch 98000/150000, 24m 50s (- 13m 10s), 2.0945\n",
      "Epoch 99000/150000, 25m 5s (- 12m 55s), 2.0433\n",
      "Epoch 100000/150000, 25m 20s (- 12m 40s), 2.0561\n",
      "Epoch 101000/150000, 25m 36s (- 12m 25s), 2.0901\n",
      "Epoch 102000/150000, 25m 51s (- 12m 9s), 2.0235\n",
      "Epoch 103000/150000, 26m 6s (- 11m 54s), 2.0271\n",
      "Epoch 104000/150000, 26m 22s (- 11m 39s), 2.0246\n",
      "Epoch 105000/150000, 26m 37s (- 11m 24s), 2.0574\n",
      "Epoch 106000/150000, 26m 52s (- 11m 9s), 1.9883\n",
      "Epoch 107000/150000, 27m 8s (- 10m 54s), 2.0295\n",
      "Epoch 108000/150000, 27m 23s (- 10m 39s), 1.9047\n",
      "Epoch 109000/150000, 27m 38s (- 10m 23s), 1.9306\n",
      "Epoch 110000/150000, 27m 54s (- 10m 8s), 2.0092\n",
      "Epoch 111000/150000, 28m 9s (- 9m 53s), 2.0051\n",
      "Epoch 112000/150000, 28m 25s (- 9m 38s), 1.9976\n",
      "Epoch 113000/150000, 28m 41s (- 9m 23s), 1.9705\n",
      "Epoch 114000/150000, 28m 56s (- 9m 8s), 1.9498\n",
      "Epoch 115000/150000, 29m 12s (- 8m 53s), 1.9500\n",
      "Epoch 116000/150000, 29m 27s (- 8m 38s), 2.0320\n",
      "Epoch 117000/150000, 29m 42s (- 8m 22s), 1.9753\n",
      "Epoch 118000/150000, 29m 58s (- 8m 7s), 1.8635\n",
      "Epoch 119000/150000, 30m 13s (- 7m 52s), 1.9525\n",
      "Epoch 120000/150000, 30m 29s (- 7m 37s), 1.9238\n",
      "Epoch 121000/150000, 30m 44s (- 7m 22s), 1.8708\n",
      "Epoch 122000/150000, 30m 59s (- 7m 6s), 1.8953\n",
      "Epoch 123000/150000, 31m 15s (- 6m 51s), 1.9219\n",
      "Epoch 124000/150000, 31m 30s (- 6m 36s), 1.8348\n",
      "Epoch 125000/150000, 31m 45s (- 6m 21s), 1.9193\n",
      "Epoch 126000/150000, 32m 1s (- 6m 5s), 1.9252\n",
      "Epoch 127000/150000, 32m 16s (- 5m 50s), 1.8289\n",
      "Epoch 128000/150000, 32m 32s (- 5m 35s), 1.9009\n",
      "Epoch 129000/150000, 32m 47s (- 5m 20s), 1.8175\n",
      "Epoch 130000/150000, 33m 2s (- 5m 5s), 1.8140\n",
      "Epoch 131000/150000, 33m 18s (- 4m 49s), 1.8556\n",
      "Epoch 132000/150000, 33m 33s (- 4m 34s), 1.8477\n",
      "Epoch 133000/150000, 33m 49s (- 4m 19s), 1.7974\n",
      "Epoch 134000/150000, 34m 4s (- 4m 4s), 1.7224\n",
      "Epoch 135000/150000, 34m 19s (- 3m 48s), 1.8235\n",
      "Epoch 136000/150000, 34m 35s (- 3m 33s), 1.7240\n",
      "Epoch 137000/150000, 34m 50s (- 3m 18s), 1.7783\n",
      "Epoch 138000/150000, 35m 6s (- 3m 3s), 1.7966\n",
      "Epoch 139000/150000, 35m 21s (- 2m 47s), 1.8333\n",
      "Epoch 140000/150000, 35m 36s (- 2m 32s), 1.7600\n",
      "Epoch 141000/150000, 35m 52s (- 2m 17s), 1.8810\n",
      "Epoch 142000/150000, 36m 7s (- 2m 2s), 1.7486\n",
      "Epoch 143000/150000, 36m 23s (- 1m 46s), 1.7822\n",
      "Epoch 144000/150000, 36m 38s (- 1m 31s), 1.7493\n",
      "Epoch 145000/150000, 36m 53s (- 1m 16s), 1.7459\n",
      "Epoch 146000/150000, 37m 9s (- 1m 1s), 1.7273\n",
      "Epoch 147000/150000, 37m 24s (- 0m 45s), 1.7278\n",
      "Epoch 148000/150000, 37m 40s (- 0m 30s), 1.7556\n",
      "Epoch 149000/150000, 37m 55s (- 0m 15s), 1.7620\n",
      "Epoch 150000/150000, 38m 10s (- 0m 0s), 1.7630\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 500\n",
    "n_layers = 1\n",
    "dropout_p = 0.05\n",
    "n_epochs = 150000\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderLSTM(input_lang.n_words, hidden_size, n_layers)\n",
    "decoder = DecoderLSTM(hidden_size, output_lang.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Configuring training\n",
    "plot_every = 200\n",
    "print_every = 1000\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every\n",
    "\n",
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    training_pair = variables_from_pair(random.choice(pairs))\n",
    "    input_variable = training_pair[0]\n",
    "    target_variable = training_pair[1]\n",
    "\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, \n",
    "                 encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = 'Epoch %d/%d, %s, %.4f' % (epoch, n_epochs, time_since(start, epoch / n_epochs), \n",
    "                                                   print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55dad5a4-ae25-41c0-ad69-09b4dfcdceaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6326a085-969f-48ff-bf75-407c4501310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variable_from_sentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = torch.LongTensor([[SOS_token]]) # SOS\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni.item()])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = torch.LongTensor([[ni]])\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3024e586-db16-453b-801e-12feaf930e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = random.choice(pairs)\n",
    "    \n",
    "    output_words = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e45951d4-b509-4b90-9663-22b334a805f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 汤姆还好吧？\n",
      "= is tom well ?\n",
      "< is tom okay ? <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0c5f418-1426-48b7-85fc-a387f563e7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'life is fun . <EOS>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(evaluate('人生是有趣的。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a2bdac9-5e5e-49e6-9ab4-0322b605b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "\n",
    "# 读取测试数据集\n",
    "with open('cn-eng-test.txt') as f:\n",
    "    lines = f.read().strip().split('\\n')\n",
    "    \n",
    "    test_pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "\n",
    "\n",
    "test_pairs_dict = collections.defaultdict(lambda : [])\n",
    "\n",
    "for pair in test_pairs:\n",
    "    test_pairs_dict[pair[0]].append(pair[1].split(' '))\n",
    "\n",
    "\n",
    "def evaluate_bleu_score():\n",
    "    candicates = []\n",
    "    references = []\n",
    "\n",
    "    for i, pair in enumerate(test_pairs_dict.items(), start=1):\n",
    "        candicate = evaluate(pair[0])\n",
    "        if candicate[-1] == '<EOS>':\n",
    "            candicate.pop(-1)\n",
    "        candicates.append(candicate)\n",
    "        references.append(pair[1])\n",
    "    \n",
    "    score = bleu_score(candicates, references)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ceb9ede-06be-495e-87f6-300e610b6504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset bleu score: 0.34046859806689506\n"
     ]
    }
   ],
   "source": [
    "print('test dataset bleu score: %s' % evaluate_bleu_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "409fa2af-05fd-4c9e-8ba8-7dd7ac230234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filepath):\n",
    "    \"\"\"预测\"\"\"\n",
    "    with open('test.txt') as f:\n",
    "        sentences =  [line.strip() for line in f.readlines()]\n",
    "\n",
    "    output_sentences = []\n",
    "    for sentence in sentences:\n",
    "        output_sentence = ' '.join(evaluate(sentence))\n",
    "        output_sentences.append(output_sentence.strip('<EOS>'))\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write('\\n'.join(output_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db6af12-1d84-454e-be62-47fc58069528",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict('result-attention.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd9011-7c3d-43f7-bc3b-4a6cc4c7c5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9e89d-3f36-48c2-b340-d4d585e3f442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4801d-0d5c-4b79-b13f-5afd1f022ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa31519-5c58-441c-aa24-011db7f33991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdddd0-0a46-41d0-bb1a-2b23543a26a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
